/**
 * PicGo Plugin: Multi-Uploader
 * Upload one image to multiple image beds in parallel with retry and Markdown summary support.
 */

module.exports = (ctx) => {
  const PLUGIN_NAME = 'picgo-plugin-multi-uploader'
  
  // ä¸æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶åçš„å›¾åºŠåˆ—è¡¨
  const NO_CUSTOM_FILENAME_BEDS = ['smms', 'imgur']
  
  // Cache original image data between beforeUpload and afterUpload phases
  let cachedImageData = null

  const registerConfig = () => [
    {
      name: 'enabledBeds',
      type: 'string',
      default: 'smms,github',
      message: 'Enabled image beds (comma-separated)',
      alias: 'Enabled Beds'
    },
    {
      name: 'unifyFileName',
      type: 'boolean',
      default: true,
      message: 'Whether to maintain a unified filename across all beds',
      alias: 'Unify Filename'
    },
    {
      name: 'retryCount',
      type: 'number',
      default: 2,
      message: 'Number of retry attempts on failure',
      alias: 'Retry Count'
    },
    {
      name: 'retryDelay',
      type: 'number',
      default: 2000,
      message: 'Delay between retries (milliseconds)',
      alias: 'Retry Delay'
    },
    {
      name: 'generateMarkdown',
      type: 'boolean',
      default: true,
      message: 'Whether to generate a Markdown summary of links',
      alias: 'Generate Markdown'
    }
  ]

  const delay = (ms) => new Promise((res) => setTimeout(res, ms))

  const getCurrentUploader = (ctx) => {
    return ctx.getConfig('picBed.uploader') || ctx.getConfig('picBed.current')
  }

  const getRealBuffer = (item) => {
    if (item.buffer) {
      return Buffer.isBuffer(item.buffer) ? item.buffer : Buffer.from(item.buffer)
    }
    if (item.base64Image) {
      return Buffer.from(item.base64Image.replace(/^data:\S+;base64,/, ''), 'base64')
    }
    return undefined
  }

  // ä» URL ä¸­æå–æ–‡ä»¶å
  const extractFilenameFromUrl = (url) => {
    if (!url) return null
    const parts = url.split('/')
    const filename = parts[parts.length - 1]
    // ç§»é™¤æŸ¥è¯¢å‚æ•°
    return filename.split('?')[0]
  }

  // ç”Ÿæˆ hash æ–‡ä»¶å
  const generateHashFilename = (ext) => {
    const hash = Date.now().toString(36) + Math.random().toString(36).substr(2, 8)
    return `${hash}${ext}`
  }

  // æ£€æŸ¥å›¾åºŠæ˜¯å¦æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶å
  const supportsCustomFilename = (bed) => {
    return !NO_CUSTOM_FILENAME_BEDS.includes(bed.toLowerCase())
  }

  const uploadWithRetry = async (bed, ctx, retryCount, retryDelay, customFilename = null) => {
    const uploader = ctx.helper.uploader.get(bed)
    if (!uploader?.handle) {
      throw new Error(`Uploader not found: ${bed}`)
    }

    for (let attempt = 0; attempt <= retryCount; attempt++) {
      try {
        // Construct isolated context for this uploader
        const clonedOutput = (cachedImageData || []).map((item) => {
          const output = {
            fileName: customFilename || item.fileName,
            extname: item.extname,
            buffer: getRealBuffer(item),
            base64Image: undefined, // Force buffer mode
            url: undefined,
            imgUrl: undefined
          }
          return output
        })

        const clonedCtx = {
          getConfig: (name) => ctx.getConfig(name),
          log: ctx.log,
          input: [...(ctx.input || [])],
          output: clonedOutput,
          helper: ctx.helper,
          emit: ctx.emit?.bind(ctx),
          request: ctx.request?.bind(ctx),
          Request: ctx.Request,
          // Pass through essential context properties
          baseDir: ctx.baseDir,
          configPath: ctx.configPath
        }

        await uploader.handle(clonedCtx)

        if (!clonedCtx.output?.length) {
          throw new Error(`Uploader ${bed} returned no valid output`)
        }

        const hasUrl = clonedCtx.output.some(i => i.url || i.imgUrl || i.image || i.source)
        if (!hasUrl) {
          throw new Error(`Uploader ${bed} returned no URL/imgUrl`)
        }

        ctx.log.info(`[${PLUGIN_NAME}] âœ… ${bed} upload successful`)
        return clonedCtx.output
      } catch (err) {
        if (attempt >= retryCount) {
          ctx.log.error(`[${PLUGIN_NAME}] âŒ ${bed} upload failed after maximum retries: ${err.message}`)
          return null
        }
        ctx.log.warn(`[${PLUGIN_NAME}] âš ï¸ ${bed} upload failed, retrying (${attempt + 1}/${retryCount})... Error: ${err.message}`)
        await delay(retryDelay)
      }
    }
  }

  /** beforeUpload: Cache original data */
  ctx.helper.beforeUploadPlugins.register(PLUGIN_NAME, {
    handle: async (ctx) => {
      // Deep copy output and save buffer/base64 to cache
      cachedImageData = (ctx.output || []).map(item => ({
        fileName: item.fileName || (Date.now() + (item.extname || '.png')),
        extname: item.extname || '.png',
        buffer: item.buffer ? Buffer.from(item.buffer) : undefined,
        base64Image: item.base64Image || undefined
      }))

      ctx.log.info(`[${PLUGIN_NAME}] Cached ${cachedImageData.length} files for upload`)
      return ctx
    }
  })

  /** afterUpload: Smart upload with unified filename support */
  ctx.helper.afterUploadPlugins.register(PLUGIN_NAME, {
    handle: async (ctx) => {
      const config = ctx.getConfig(PLUGIN_NAME) || {}
      if (!config.enabledBeds) {
        ctx.log.warn(`[${PLUGIN_NAME}] No image beds configured`)
        cachedImageData = null
        return ctx
      }

      const allBeds = config.enabledBeds.split(',').map(b => b.trim()).filter(Boolean)
      const current = getCurrentUploader(ctx)
      const backupBeds = allBeds.filter(b => b !== current)

      if (backupBeds.length === 0) {
        ctx.log.warn(`[${PLUGIN_NAME}] No backup beds found, skipping`)
        cachedImageData = null
        return ctx
      }

      // è·å–ä¸»å›¾åºŠçš„è¾“å‡ºç»“æœ
      const primaryOutput = Array.isArray(ctx.output) ? ctx.output.map(i => ({ ...i, uploader: current || 'primary' })) : []
      
      // åˆ†ç±»ï¼šæ”¯æŒ/ä¸æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶åçš„å›¾åºŠ
      const noCustomFilenameBeds = backupBeds.filter(b => !supportsCustomFilename(b))
      const customFilenameBeds = backupBeds.filter(b => supportsCustomFilename(b))

      let unifiedFilename = null
      let canUnifyFilename = config.unifyFileName !== false

      // æ£€æŸ¥ä¸»å›¾åºŠæ˜¯å¦æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶å
      const primarySupportsCustom = supportsCustomFilename(current)

      if (canUnifyFilename) {
        // è®¡ç®—æ‰€æœ‰ä¸æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶åçš„å›¾åºŠï¼ˆåŒ…æ‹¬ä¸»å›¾åºŠï¼‰
        const allNoCustomBeds = [...noCustomFilenameBeds]
        if (!primarySupportsCustom) {
          allNoCustomBeds.push(current)
        }

        if (allNoCustomBeds.length > 1) {
          // å¤šä¸ªä¸æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶åçš„å›¾åºŠï¼Œæ— æ³•ç»Ÿä¸€
          ctx.log.warn(`[${PLUGIN_NAME}] âš ï¸ Multiple beds don't support custom filenames (${allNoCustomBeds.join(', ')}). Unified filename disabled.`)
          canUnifyFilename = false
        } else if (allNoCustomBeds.length === 1) {
          // åªæœ‰ä¸€ä¸ªä¸æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶åçš„å›¾åºŠ
          const noCustomBed = allNoCustomBeds[0]
          
          if (noCustomBed === current) {
            // ä¸»å›¾åºŠä¸æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶åï¼Œä»ä¸»å›¾åºŠè¾“å‡ºä¸­æå–æ–‡ä»¶å
            if (primaryOutput.length > 0) {
              const url = primaryOutput[0].url || primaryOutput[0].imgUrl
              unifiedFilename = extractFilenameFromUrl(url)
              ctx.log.info(`[${PLUGIN_NAME}] ğŸ“ Extracted filename from ${current}: ${unifiedFilename}`)
            }
          } else {
            // å¤‡ä»½å›¾åºŠä¸­æœ‰ä¸€ä¸ªä¸æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶åï¼Œéœ€è¦å…ˆä¸Šä¼ åˆ°å®ƒ
            ctx.log.info(`[${PLUGIN_NAME}] ğŸš€ Uploading to ${noCustomBed} first (no custom filename support)...`)
            
            const result = await uploadWithRetry(noCustomBed, ctx, config.retryCount || 2, config.retryDelay || 2000)
            
            if (result && result.length > 0) {
              const url = result[0].url || result[0].imgUrl
              unifiedFilename = extractFilenameFromUrl(url)
              ctx.log.info(`[${PLUGIN_NAME}] ğŸ“ Extracted filename from ${noCustomBed}: ${unifiedFilename}`)
              
              // å°†è¿™ä¸ªç»“æœæ·»åŠ åˆ°è¾“å‡ºä¸­ï¼Œå¹¶ä»å¾…ä¸Šä¼ åˆ—è¡¨ä¸­ç§»é™¤
              primaryOutput.push(...result.map(i => ({ ...i, uploader: noCustomBed })))
            }
            
            // ä»å¤‡ä»½åˆ—è¡¨ä¸­ç§»é™¤å·²ä¸Šä¼ çš„å›¾åºŠ
            const remainingNoCustomBeds = noCustomFilenameBeds.filter(b => b !== noCustomBed)
            noCustomFilenameBeds.length = 0
            noCustomFilenameBeds.push(...remainingNoCustomBeds)
          }
        } else {
          // æ‰€æœ‰å›¾åºŠéƒ½æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶åï¼Œç”Ÿæˆ hash æ–‡ä»¶å
          const ext = cachedImageData[0]?.extname || '.png'
          unifiedFilename = generateHashFilename(ext)
          ctx.log.info(`[${PLUGIN_NAME}] ğŸ“ Generated unified filename: ${unifiedFilename}`)
        }
      }

      // ä¸Šä¼ åˆ°å‰©ä½™çš„å¤‡ä»½å›¾åºŠ
      const remainingBeds = [...noCustomFilenameBeds, ...customFilenameBeds]
      
      if (remainingBeds.length > 0) {
        ctx.log.info(`[${PLUGIN_NAME}] ğŸš€ Parallel uploading to: ${remainingBeds.join(', ')}${unifiedFilename ? ` (filename: ${unifiedFilename})` : ''}`)

        const tasks = remainingBeds.map(bed => {
          // åªå¯¹æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶åçš„å›¾åºŠä½¿ç”¨ç»Ÿä¸€æ–‡ä»¶å
          const filenameToUse = supportsCustomFilename(bed) ? unifiedFilename : null
          return uploadWithRetry(bed, ctx, config.retryCount || 2, config.retryDelay || 2000, filenameToUse)
            .then(output => ({ bed, output }))
        })

        const results = await Promise.allSettled(tasks)

        const backupOutputs = results
          .filter(r => {
            if (r.status !== 'fulfilled') {
              ctx.log.error(`[${PLUGIN_NAME}] Backup task exception:`, r.reason || 'unknown')
              return false
            }
            if (!r.value?.output) {
              ctx.log.warn(`[${PLUGIN_NAME}] ${r.value.bed} returned empty results`)
              return false
            }
            return true
          })
          .flatMap(r => r.value.output.map(i => ({ ...i, uploader: r.value.bed })))

        primaryOutput.push(...backupOutputs)
      }

      ctx.output = primaryOutput
      ctx.log.success(`[${PLUGIN_NAME}] ğŸ‰ Multi-bed upload completed (${primaryOutput.length} results)`)

      if (config.generateMarkdown) {
        const markdown = generateMarkdownTable(primaryOutput)
        ctx.log.info('\nğŸ“‹ Markdown Link Summary:\n')
        console.log(markdown)
      }

      cachedImageData = null
      return ctx
    }
  })

  function generateMarkdownTable(images) {
    if (!images?.length) return ''
    
    const grouped = images.reduce((acc, img) => {
      const fname = img.fileName || img.origin?.fileName || 'image'
      if (!acc[fname]) acc[fname] = []
      acc[fname].push(img)
      return acc
    }, {})

    return Object.entries(grouped).map(([filename, imgs]) => {
      const rows = imgs.map(img => {
        const url = img.url || img.imgUrl || img.image || img.source || ''
        return `| ${img.uploader || '-'} | ![](${url}) | [${url}](${url}) |`
      }).join('\n')
      
      return `### ğŸ–¼ï¸ ${filename}\n\n| Bed | Preview | Link |\n|------|------|------|\n${rows}\n`
    }).join('\n')
  }

  return {
    register: registerConfig
  }
}
